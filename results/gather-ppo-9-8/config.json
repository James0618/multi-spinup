{
    "actor_critic":	"CNNActorCritic",
    "args":	{
        "namespace(attack_food_reward=0.5, attack_opponent_reward=0.5, attack_penalty=-0.05, communicate=False, communication_range=2, cpu=6, dead_penalty=-1.0, enemy_policy='ppo', epochs=500, gamma=0.995, hidden_dim=128, input_shape=[torch.Size([9, 13, 13]), torch.Size([35])], map_size=80, max_agents={'red': 0, 'blue': 0}, max_cycle=160, message_size=5, n_actions=33, observation_shape=torch.Size([9, 13, 13]), plot_topology=False, seed=0, state_shape=torch.Size([3, 80, 80]), step_reward=-0.005, steps_per_epoch=120000, view_range=6)":	{
            "attack_food_reward":	0.5,
            "attack_opponent_reward":	0.5,
            "attack_penalty":	-0.05,
            "communicate":	false,
            "communication_range":	2,
            "cpu":	6,
            "dead_penalty":	-1.0,
            "enemy_policy":	"ppo",
            "epochs":	500,
            "gamma":	0.995,
            "hidden_dim":	128,
            "input_shape":	[
                [
                    9,
                    13,
                    13
                ],
                [
                    35
                ]
            ],
            "map_size":	80,
            "max_agents":	{
                "blue":	"0",
                "red":	"0"
            },
            "max_cycle":	160,
            "message_size":	5,
            "n_actions":	"33",
            "observation_shape":	[
                9,
                13,
                13
            ],
            "plot_topology":	false,
            "seed":	0,
            "state_shape":	[
                3,
                80,
                80
            ],
            "step_reward":	-0.005,
            "steps_per_epoch":	120000,
            "view_range":	6
        }
    },
    "clip_ratio":	0.2,
    "env_fn":	"<function run.<locals>.<lambda> at 0x7f53c5654f28>",
    "epochs":	500,
    "exp_name":	"gather-ppo-9-8",
    "gamma":	0.995,
    "lam":	0.97,
    "logger":	{
        "<spinup.utils.logx.EpochLogger object at 0x7f53c530beb8>":	{
            "epoch_dict":	{},
            "exp_name":	"gather-ppo-9-8",
            "first_row":	true,
            "log_current_row":	{},
            "log_headers":	[],
            "output_dir":	"/home/drl/PycharmProjects/multi-spinup/results/gather-ppo-9-8",
            "output_file":	{
                "<_io.TextIOWrapper name='/home/drl/PycharmProjects/multi-spinup/results/gather-ppo-9-8/progress.txt' mode='w' encoding='UTF-8'>":	{
                    "mode":	"w"
                }
            }
        }
    },
    "logger_kwargs":	{
        "exp_name":	"gather-ppo-9-8",
        "output_dir":	"/home/drl/PycharmProjects/multi-spinup/results/gather-ppo-9-8"
    },
    "max_ep_len":	1000,
    "pi_lr":	0.0004,
    "save_freq":	10,
    "seed":	0,
    "steps_per_epoch":	120000,
    "target_kl":	0.01,
    "train_pi_iters":	50,
    "train_v_iters":	50,
    "vf_lr":	0.0008
}